---
layout: post
title:  "TCO and kdb+"
date:   2022-01-10
tags: kdb q functional-programming
toc: true
---

I often heard in sales pitches that a certain DBMS excels in *total cost of ownership* (TCO). My brain works in a way that it believes any technical statement only if it is demonstrated by an example. I saw several examples that demonstrates the elegance and simplicity of the kdb+ language, but recently I came across a FAANG interview question that inspired me to write about this topic.

In this article, I dissect a FAANG interview question, examine how can it be solved in SQL and kdb+ and how it likely occurs in real life. I will show the complexity explosion with the traditional SQL-based solution and then show how complexity is kept under control with kdb+.


## Problem statement

The following description is taken from [Thoufiq Mohammed's blog](https://techtfq.com/blog/real-sql-interview-question-asked-by-a-faang-company).

We want to generate an inventory age report which would show the distribution of remaining inventory across the length of time the inventory has been sitting at the warehouse. We are trying to classify the inventory on hand across the below 4 buckets to denote the time the inventory has been lying in the warehouse.

   * 0-90 days old
   * 91-180 days old
   * 181-270 days old
   * 271 – 365 days old

For example, the warehouse received 100 units yesterday and shipped 30 units today, then there are 70 units which are a day old.

The warehouses use FIFO (first in first out) approach to manage inventory, i.e., the inventory that comes first will be sent out first.

### sample input

| ID     |  OnHandQuantity|  OnHandQuantityDelta| Direction | EventTime |
|--------|---------------:|--------------------:|------------|------------|
| TR0013 |             278|                   99| OutBound   | 2020-05-25 |
| TR0012 |             377|                   31| InBound    | 2020-05-24 |
| TR0011 |             346|                    0| OutBound   | 2020-05-24 |
| TR0010 |             346|                    2| OutBound   | 2020-05-23 |
| TR009  |             348|                  102| InBound    | 2020-04-25 |
| TR008  |             246|                   43| InBound    | 2020-04-25 |
| TR007  |             203|                    2| OutBound   | 2020-02-25 |
| TR006  |             205|                  129| OutBound   | 2020-02-18 |
| TR005  |             334|                    1| OutBound   | 2020-02-18 |
| TR004  |             335|                   27| OutBound   | 2020-01-29 |
| TR003  |             362|                  120| InBound    | 2019-12-31 |
| TR002  |             242|                    8| OutBound   | 2019-05-22 |
| TR001  |             250|                  250| InBound    | 2019-05-20 |

For example, on 20<sup>th</sup> May 2019, 250 units were inbounded. On 22<sup>nd</sup> May 2019, 8 units were shipped out (outbound) from the inventory, reducing inventory on hand to 242 units. On 31<sup>st</sup> December, 120 units were further inbounded increasing the inventory on hand from 242 to 362. On 29<sup>th</sup> January 2020, 27 units were shipped out reducing the inventory on hand to 335 units. On 29<sup>th</sup> January, of the 335 units on hands, 120 units were 0-90 days old (29 days old) and 215 units were 181-270 days old (254 days old).

Columns:

   * **ID**: of the log entry
   * **OnHandQuantity**: Quantity in warehouse after an event
   * **OnHandQuantityDelta**: Change in on-hand quantity due to an event
   * **Direction**: Inbound – inventory being brought into the warehouse; Outbound – inventory being sent out of warehouse
   * **event_date**: date of event

The data is sorted with latest entry at top.

### Expected output

The expected output for the sample input is

| 0-90 days old | 91-180 days old | 181-270 days old | 271 – 365 days old |
| ---: | ---: | ---: | ---: |
| 176 | 102 | 0 | 0 |

## A solution in SQL
The solutions for PostgreSQL, MySQL, MSSQL and SQL for Oracle databases are quite similar. Here I display Thoufiq's PostgreSQL solution.

```sql
WITH WH as
		(select * from warehouse order by event_datetime desc),
	days as
		(select event_datetime, onhandquantity
		 	  , (event_datetime - interval '90 DAY') as day90
		 	  , (event_datetime - interval '180 DAY') as day180
		 	  , (event_datetime - interval '270 DAY') as day270
		 	  , (event_datetime - interval '365 DAY') as day365
		 from WH limit 1),
	inv_90_days as
		(select coalesce(sum(WH.OnHandQuantityDelta), 0) as DaysOld_90  /* Get the total InBound inventories in the last 90 days */
		 from WH cross join days
		 where WH.event_datetime >= days.day90
		 and event_type = 'InBound'),
	inv_90_days_final as
		(select case when DaysOld_90 > onhandquantity then onhandquantity  /* If InBound inventories is greater than curent total inventories then curent total inventories is the remaining inventories */
					else DaysOld_90
	   		   end as DaysOld_90
		from inv_90_days x
		cross join days),

	inv_180_days as
		(select coalesce(sum(WH.OnHandQuantityDelta), 0) as DaysOld_180  /* Get the total InBound inventories between the last 90 and 180 days */
		 from WH cross join days
		 where WH.event_datetime between days.day180 and days.day90
		 and event_type = 'InBound'),
	inv_180_days_final as
		(select case when DaysOld_180 > (onhandquantity - DaysOld_90) then (onhandquantity - DaysOld_90)
					else DaysOld_180
	   		   end as DaysOld_180
		from inv_180_days x
		cross join days
		cross join inv_90_days_final),

	inv_270_days as
		(select coalesce(sum(WH.OnHandQuantityDelta), 0) as DaysOld_270  /* Get the total InBound inventories between the last 180 and 270 days */
		 from WH cross join days
		 where WH.event_datetime between days.day270 and days.day180
 		 and event_type = 'InBound'),
	inv_270_days_final as
		(select case when DaysOld_270 > (onhandquantity - (DaysOld_90 + DaysOld_180)) then (onhandquantity - (DaysOld_90 + DaysOld_180))
					else DaysOld_270
	   		   end as DaysOld_270
		from inv_270_days x
		cross join days
		cross join inv_90_days_final
		cross join inv_180_days_final),

	inv_365_days as
		(select coalesce(sum(WH.OnHandQuantityDelta), 0) as DaysOld_365  /* Get the total InBound inventories between the last 270 and 365 days */
		 from WH cross join days
		 where WH.event_datetime between days.day365 and days.day270
		 and event_type = 'InBound'),
	inv_365_days_final as
		(select case when DaysOld_365 > (onhandquantity - (DaysOld_90 + DaysOld_180 + DaysOld_270)) then (onhandquantity - (DaysOld_90 + DaysOld_180 + DaysOld_270))
					else DaysOld_365
	   		   end as DaysOld_365
		from inv_365_days x
		cross join days
		cross join inv_90_days_final
		cross join inv_180_days_final
		cross join inv_270_days_final)

select DaysOld_90 as "0-90 days old"
	 , DaysOld_180 as "91-180 days old"
	 , DaysOld_270 as "181-270 days old"
	 , DaysOld_365 as "271-365 days old"
from inv_90_days_final
cross join inv_180_days_final
cross join inv_270_days_final
cross join inv_365_days_final
cross join days;
```

Each bucket e.g. "0-90 days old" requires two temporal tables (`inv_90_days` and `inv_90_days_final`).

## A solution in kdb+

We can get the solution in four lines of code

```q
inB: exec EventTime!OnHandQuantityDelta from t where Direction=`InBound

res: where[res>0]#res: inB {x - deltas y & sums x}/ exec OnHandQuantityDelta from t where Direction=`OutBound

bucket: `s#(0 91 181 271)!("0-90 days old"; "91-180 days old"; "181-270 days old"; "271-365 days old")

select sum qty by bucket days from ([] days: 2020.05.25-key res; qty: value res)
```

I will provide more explanation about the kdb+ solution in later chapter. Here I just collect a few statistics about SQL and kdb+ solution.

| solution | nr of lines | nr of words | nr of characters | nr of parenthesis | max depth of nesting |
| --- | ---: | ---: | ---: | ---: | ---: |
| SQL | 71 | 355 | 2521 | | |
| kdb+ | 4 | 60 | 369 | | |

We can see that the SQL solution requires 5 times more typing. SQL solution does not fit into a single page, thus the reader need to scroll up and down when trying to understand the solution. This scrolling causes micro interruption, fragments the code digestion and elongates the understanding. Understanding the code quickly is crucial in quick outage resolution.

One basic principle of kdb+ is the brevity. Also, it strives to minimize nested statement since the brain is good at sequential processing the information. Jumping up and down in the execution stack is for computers.

## The real life

This exercise is great for an interview question, I still regard it as a simplification of real the life. In reality the data analyst will receive the following requests from the business/product management.

### Custom buckets, no bucketing

Today we care about binning by 90 days (cca. a quarter), tomorrow somebody will require you to bucket by a month (cca by 30 days). You will need to manually rewrite the query and replace the four temporal tables by, er, 24 temporal tables.

Somebody wont need bucketing at all. She will need the exact distribution. The sum of the quantities in each bucket is just one aggregation. Maybe she also needs the max values, the standard deviation, etc. These metrics may shed valuable insights of the business domain.

Finally, somebody will ask you for a generic solution and would like to provide the bucketing as a parameter, e.g. via another table.

### Overall distribution

The result contains the distribution of the inventory asof 2020-05-25. Is the distribution today representative for the whole year? How much quantity do I store for N days? The 8 quantity that was sent out on 2019-05-22 did not play any part in the calculation. They were in the inventory for two days. Is the two days an average duration? If I am an online merchant and logistics is a critical part of my business, then I need to efficiently balancing the storage.


### Multiple product
In reality, there are multiple products in our business. There is a product identifier and all the questions above might be interesting for all products. We can generalize the original problem. The output should no longer have a single row, but we expect as many rows as many product exist.

Simple aggregations can easily be answered by a GROUP BY clause of the SELECT statement. Unfortunately, we don't face a simple problem.

Furthermore, products can be split into multiple categories. Meaningful bucketing may depend on the category. The time horizon for e.g. a dairy product and electronic appliances are probably different.

## The path from SQL to kdb+

You probably feel joy that you could come up with an SQL solution for the original problem. However, in real life and due to the expectations described above you will soon realize that the SQL solution is extremely hard to maintain and generalize. At this phase you drop the idea of implementing the business logic in SQL and only fetch the raw data from the database. You move the business logic to another layer implemented e.g. in Python, Java, C++, go, etc. that are designed to cope with complex problems.

A fully featured programming language has lot of features. You can modularize your code by creating local variables, classes, and function. A function can take parameters - recall the requirement of custom buckets. Also, you can use data structures other than tables, like lists (matrices), sets, dictionaries, etc.

Once you move certain logic out of the DB layer, consistency becomes an issue and you will be tempted to move out more logic. This, however, has some flip sides. You will need to learn, maintain, update and test two systems. You need to make sure that integration tests are in place. The dependencies need to be built into the CI/CD tools. One should not change a schema without changing the business logic. Now your database and business layer need a synchronized production rollout.

Your database layer is designed for serving multiple users. You need to take care of the client requests and load balancing.

The programming language that you choose can probably do data analysis but likely it is not designed from the ground to do it. You can use some external data frame libraries like Pandas, dplyr to simplify some operation. You are just increasing your tech stack and the complexity that you need to maintain. To guarantee the stability of your complex system you need to devote significant amount of time to create test cases. Maintaining these tests slows down development and you became less reactive to the business needs.

Finally, you move the calculation away from the data. You move the raw data as opposed to the results only. There will be more data traverse, serialization/deserialization cost impacting network and CPU and memory usage. You may need to meet strict security expectations. This adds an extra encryption, decryption to the data in flight and extends query response times.

Welcome, your TCO got unleashed!

**You realize that all pain is coming from the fact that the DBMS query language is not expressive enough and the business logic in SQL statements is not maintainable. This is the fundamental problem that kdb+ addresses. The language was designed from data analysis from the ground. If offers a Turing complete, expressive language that is executed in the closest proximity to the data. Therefore it is extremely fast.**

Most DBMS vendors understand the limitation of SQL and the complexity explosion that it causes. They try to extend the language. ANSI SQL window functions were added to the standard in 2003. Google introduced Standard SQL to BigQuery to support lists and JSON-s in a cell and functions (e.g. UNNEST) that helps processing these cells. PostgreSQL even added recursive queries to make the query language Turing complete. The list of new extension attempts goes on but the fundamental problem remains.

## The kdb+ solution

In this section, I will explain some kdb+ techniques used in the solution and see how these techniques help in the real life to answer more complex questions.

### Custom bucketing, stepped dictionary

The kdb+ script generate the exact distribution first and then applies bucketing. The bucket lower bounds and labels are stored in a stepped dictionary.

```q
q) bucket: `s#(0 91 181 271)!("0-90 days old"; "91-180 days old"; "181-270 days old"; "271-365 days old")
q) bucket
0  | "0-90 days old"
91 | "91-180 days old"
181| "181-270 days old"
271| "271-365 days old"
```

The key of the stepped dictionary is an orders list. If you index a normal dictionary with an element that is not among the keys, then you get a null - empty string in our case. For stepped dictionaries you get the value for the highest key that are lower than your indexing parameter.

```q
q) bucket 20
"0-90 days old"
```

Note that in kdb+ you can omit square brackets when indexing... they are just technical noise after all.

Let us assume that we have a table called `distr` that stores the exact distribution of lengths in a table.

```q
q) distr
days qyt
--------
52   12
66   481
93   94
95   45
187  851
210  487
240  732
245  995
```

A beauty of the kdb+ query language is that you can plug custom functions, dictionaries, list anywhere in a select statement. For example, you can generate a bucket column:

```q
q)select qty, bucket: bucket days from distr
qty bucket
----------------------
366 "91-180 days old"
347 "91-180 days old"
989 "91-180 days old"
704 "181-270 days old"
496 "181-270 days old"
489 "181-270 days old"
550 "181-270 days old"
416 "271-365 days old"
```

Or you can group by bucket and do an aggregation

```q
q)select sum qty by bucket days from distr
days              | qty
------------------| ----
"181-270 days old"| 2239
"271-365 days old"| 416
"91-180 days old" | 1702
```

If the only requirement is to pass a custom bucket then you can create a simple function that accepts a single bucket parameter. If an empty bucket is passed then no bucketing should be applied.

```q
inventoryDistr: {[bucket]
  if[not type bucket; '"bucket should be a dictionary!"];
  if[(0 < count bucket) and not `s = attr key bucket; '"the keys of the bucket must be sorted or empty."];

  res: where[res>0]#res: (exec EventTime!OnHandQuantityDelta from t where Direction=`InBound)
    {x - deltas y & sums x}/ exec OnHandQuantityDelta from t where Direction=`OutBound;

  distr: ([] days: last[t `EventTime]-key res; qty: value res);
  if[0 = count bucket; :`days xkey distr];
  :select sum qty by bucket days from distr;
  }
```

### Dictionaries and lists by select statements
A select statement works on a table and returns a table. In kdb+ you can easily generate lists and dictionaries as well. Just replace `select` with `exec`.

Let us get a list first

```q
q)select OnHandQuantityDelta from t where Direction=`InBound
OnHandQuantityDelta
-------------------
31
102
43
120
250

// obtaining a list instead of a table
q)exec OnHandQuantityDelta from t where Direction=`InBound
31 102 43 120 250h
```

then a dictionary next

```q
q)inB: exec EventTime!OnHandQuantityDelta from t where Direction=`InBound
q)inB
2020.05.24D22:00:00.000000000| 31
2020.04.25D18:00:00.000000000| 102
2020.04.25D02:00:00.000000000| 43
2019.12.31D02:00:00.000000000| 120
2019.05.20D00:45:00.000000000| 250
```

The output can be assigned to variables and as we saw in the previous section list, dictionaries (even matrices) can be plugged into select statements to do more complex analysis.

### vector programming

q/kdb+ is a vector programming language. This allows a convenient and sparse notation that reflects the business intention. Alternatives are creating loops and iteration. If `x` is an atom, `y` is a list, then it simpler to write `z: x+y` to add `x` to each element to `y` to get a new list `z`, than

```python
z = []
for e in y:
      z.append(x + e)
```

Let us see how vector operations help in updating the inventory if an outbound event occurs. For simplification we ignore dates for now and assume that the inventory is just a list of quantities representing a FIFO. We need to create a new list by subtracting the outbound quantity from the inventory in a first in, first out manner. Our sample inventory looks like this

```q
q)inventory
250 120 43 102 31
```

Let us assume that the outbound quantity is 380. First we take 250 from the first element. 380-250=130 quantity is left to fill so we use all 120 from the second element. Only a portion of the third element is needed, i.e. 380-250-120 that equals 10 is less than 43. The resulting inventory is

```q
q) inventoryUpdated
0 0 33 102 31
```

Optionally we can get rid of the zeros, they won't contribute to calculations in the future.

The solution in kdb+ uses vector operations only. You can read about [FIFO allocation](https://code.kx.com/q4m3/1_Q_Shock_and_Awe/#114-example-fifo-allocation) in kdb+ introductory book [Q for Mortals](https://code.kx.com/q4m3/).

First, we calculate the cumulative sum of quantities.

```q
q) sums inventory
250 370 413 515 546i
```

We level off this sequence at 380 by using minimum operator denoted by `&`. Similar to most operator, `&` performns element wise minimum if either parameter is a list.

```q
q) 380&sums inventory
250 370 380 380 380
```

Let us unwind the result to get the quantities we need to take from each element. We need to calculate the difference of subsequent elements

```q
q) deltas 380&sums inventory
250 120 10 0 0
```

to get the remaining inventory, we subtract this allocation from the original inventory.

```q
q) inventory - deltas 380&sums inventory
0 0 33 102 31
```

We are wrapping this logic into a binary lambda `{x - deltas y & sums x}` by implicit parameters `x`, `y`.

### Polymorphism

What happens if the inventory is not a list, but a kdb+ dictionary and we use our binary lambda

```q
q) inB
2020.05.24D22:00:00.000000000| 250
2020.04.25D18:00:00.000000000| 102
2020.04.25D02:00:00.000000000| 43
2019.12.31D02:00:00.000000000| 120
2019.05.20D00:45:00.000000000| 250

q){x - deltas y & sums x}[inB; 380]
2020.05.24D22:00:00.000000000| 0
2020.04.25D18:00:00.000000000| 0
2020.04.25D02:00:00.000000000| 15
2019.12.31D02:00:00.000000000| 120
2019.05.20D00:45:00.000000000| 250
```

Wow, it works as expected! What kind of magic happens here?

In engineer's mind an array is a block of memory containing scalars of the same type. It may have a capacity and a size. kdb+ follows the notation invented by a mathematician. In a mathematician's mind, an array is a function from a set of indices to numbers, characters, strings, etc. Arrays are special dictionaries in which the keys are indices. Arrays, dictionaries and functions are members of a big family. No wonder that kdb+ strives to implement **polymorphism** at the highest level. For example, list indexing, dictionary lookup or function call, all denoted by square bracket, i.e. in expression `x[5]` variable `x` can be anything. In `x + y`, the two variables can not only be scalars and list, but dictionaries are also accepted. We already saw that in expression

```q
select f c from t
```

variable `f` is not necessarily a function, but it can be a dictionary (or a list if column `c` stores indices).

Demonstrating polymorphism in kdb+ is not in scope for this paper, but reader can get the idea how it simplifies the code and let the developers focus on the business logic instead of wrangling with data structure conversions and loops.

### Functional programming

The most well-known functional programming functions in Python are `map`, `filter` and `reduce`. Function `reduce` is called `over` and denoted by `/` in kdb+. It is an iterator. A sibling of `over` is function `scan` (denoted by `\`) that returns the result of every invocation of your function (not just the last as `over`). We already used `scan` implicitly. Function `sums` is implemented by `scan`

```q
q) sums
+\
```

Another iterator that we already used is `each prior` that applies a binary function between each item of a list and its preceding item. It is denoted by `':`. See the definition of `deltas` that uses the minus operator as the binary function.

```q
q) deltas
-':
```

We are using `over` explicitly when iteratively call our lambda over the list of outbound quantities. In kdb+ `over` also handles binary functions. In each iteration the first parameter of the function comes from the output of the previous invocations.

```q
q) inB: (exec EventTime!OnHandQuantityDelta from t where Direction=`InBound)
q) outB: exec OnHandQuantityDelta from t where Direction=`OutBound
q) inB {x - deltas y & sums x}/ outB
```

This returns the exact distribution after the last outbound quantity was processed. It starts with the inventory initialized with the dictionary of the inbound quantities and takes outbound quantities one by one and calls the FIFO lambda.

## Generalization of the problem

Let us examine how simple it is to extend the kdb+ solution to handle a real-life extension of the problem. We interested in the overall distribution of length not just asof the last day.



## Performance
